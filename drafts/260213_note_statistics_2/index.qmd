---
title: "Stat4Bio | 2. Probability and Distribution"
date: "2026-02-13"
categories: [statistics, notes, probability, distribution, draft, EN]
---

## Probability

> 'the nature and degree of the uncertainty may itself be capable of rigorous expression…' - R. A. Fisher

## Statistics

	• Data exploration and analysis
	• Inductive inference with probability
	• Quantification of evidence and uncertainty

### Example 1

Goal: determine the conc. of quinine in a sample of tonic water by fluorescence.
Method: 


Q: how precise is the resulting estimate?


### Example 2

Goal: children that have + response to a pertussis antigen: 
	• Vaccinated with DTaP-HBV: 3/38 (8%)
	• History of pertussis infection: 5/21 (24%)
Q: how precisely can we estimate the chance of a positive response given vaccination? 
Are the above rates truly different?

### Example 3

Place tick on clay island surrounded by water, with 2 capillary tubes: one treated with deer-gland-substance, one untreated.

Q: Is the tick more likely to go to the treated tube? Do the sex of the tick or deer, or the leg from which gland substance was obtained, have an effect?

## Probability

A branch of mathematics concerning the study of random processed.
-> random does not mean haphazard!
	• Degree of belief
	• Long term frequency

## The set-up

Experiment: a well-defined process with an uncertain outcome.
	-> Draw 2 balls with replacement from an urn containing 4 red & 6 black balls. 
Sample Space S: the set of possible outcomes.
	-> {RR, RB, BR, BB}
Event: A set of outcomes from the sample space (a subset of S).
	-> {the first ball is red} = {RR, RB}
Events are said to occur if one of the outcomes they contain occurs. Probabilities are assigned to events.

Probability rules
0<= Pr(A) <=1	for any event A
Pr(S) = 1	where S is the sample space
Pr(A or B) = Pr(A) + Pr(B) 	if A and B are mutually exclusive
Pr(not A) = 1 - Pr(A)	complement rule

Sets

## Conditional Probability

Pr(A|B) = probability of A given B = Pr(A∪B)/Pr(B)
	• A∪B = A and B (union)
Bayes Rules
	• Multiplication rule: Pr(A∪B) = Pr(A) * Pr(B|A) = Pr(B) * Pr(A|B)
	• Pr(A) = Pr(A and B) + Pr(A and not B)
		= Pr(B)*Pr(A|B) + Pr(not B)*Pr(A|not B)
	• Pr(B) = Pr(B and A) + Pr(B and not A)
		= Pr(A)*Pr(B|A) + Pr(not A)*Pr(B|not A)
	• Pr(A|B) = Pr(A and B)/Pr(B) = Pr(A)*Pr(B|A)/Pr(B) 
		= Pr(A)*Pr(B|A)/{Pr(A)*Pr(B|A)+Pr(notA)*Pr(B|notA)}
	• A and B are independent if Pr (A∪B) = Pr(A) * Pr(B)
		○ If A and B are independent, Pr(A|B) = Pr(A), Pr(B|A) = Pr(B)
		
Diagnostics

Given disease/no disease…

	• Sensitivity: Pr(positive test | disease) = TP/TP+FN
	• Specificity: Pr(negative test | no disease) = TN/TN+FP
Given positive/negative test result…
	• Positive Predictive Value: Pr(disease | positive test) = TP/TP+FP
	• Negative Predictive Value: Pr(no disease | negative test) = TN/TN+FN

Example: 

Assume that some disease has a 0.1% prevalence in the population. Assume we have a test kit for that disease that works with 99% sensitivity and 99% specificity. What is the probability of a person having the disease given the test result is positive, if we randomly select a subject from 

Answer: 

→  the general population? 

Given the test result is positive ~ we are asking the positive predictive value.
0.1% prevalence: TP+FN/TN+FP = 0.001
99% sensitivity: TP/TP+FN = 0.99
99% specificity: TN/TN+FP = 0.99
Let TP+FN = x, then FP + TN = 1000x, TP = 0.99x, TN = 990x, FP = 10x
Positive predictive value = TP/TP+FP = 0.99x/0.99x+10x ≈ 9%

→  a high risk sub-population with 10% disease prevalence? 

Similarly,
10% prevalence = TP+FN/TN+FP = 0.1
Let TP+FN = x, then FP + TN = 10x, TP = 0.99x, TN = 9.9x, FP = 0.1x
Positive predictive value = TP/TP+FP = 0.99x/0.99x+0.1x ≈ 90%

## Bayes Rule in the context of Diagnostics

Pr(A|B) = Pr(A and B)/Pr(B) 
	= Pr(A)*Pr(B|A)/Pr(B) 
	= Pr(A)*Pr(B|A)/[Pr(A)*Pr(B|A)+Pr(notA)*Pr(B|notA)]
	
A = disease, B = positive test result
Then…
Positive predictive value 
	= prevalence*sensitivity/probability of positive test result
	= prevalence*sensitivity/[prevalence*sensitivity+(1-prevalence)*(1-specificity)]
	
## Using this in the example before…

When prevalence = 0.1%, sensitivity = specificity = 99%, 
Positive predictive value 
	= 0.1%*99%/(0.1%*99%+99.9%*1%)
	= 0.00099/(0.00099+0.00999)
	= 0.00099/0.01098
	= 9%
	
Random Variables and Distributions
'flip the coin' 0, 0, 1, 1, … -> take average

Deer ticks example
Are they attracted by deer-gland-substance?
Suppose that 21/30 deer ticks go to the deer-gland-substance treated rod, while the other 9 go to the control rod. Would this be a reasonable result if the deer ticks were choosing between the rods completely at random?

Mouse survival following treatment
Dose the treatment have an effect?
Suppose that 15/30 control mice die, while 8/30 treatment mice die. If the probability that a control mouse dies the same as the probability that a treatment mouse dies?

-> deduction method: null hypothesis = pure probability.

Random variables
	- Discrete: take values in a countable set (e.g., the positive integers)
	- Continuous: take values in an interval (e.g., [0, 1] or the real line)
Random variables may also be partly discrete and partly continuous


Probability Function p(x)
Consider a discrete random variable X, the probability function (=probability distribution, probability mass function) of X is
	p(x)=Pr⁡(X=x)
While…
p(x) ≥ 0 for all x -> probability must be positive
∑p(x) =1 -> the sum of all probability functions should be 1

Cumulative distribution function (CDF)
	F(x) = Pr(X ≤ x)

Binomial Random Variable
Prototype
-> parameters: n and p
	• The number of heads in n independent tosses of a coin, where Pr(heads) = p for each toss.
	• Similarly… an urn containing red balls and black balls, and suppose that p is the proportion of red balls. Consider the number of red balls in n random draw with replacement from the urn. 
	
Probability Function of a Binomial(n,p) distribution

X~Binomial(n, p)

Binomial Coefficient

$$(█(n@k))=n!/k!(n−k)!$$

## Probability Function

$$Pr⁡(X=k)=(█(n@k)) p^k (1−p)^(n-k)$$

Example: let n = 9, p = 0.2

$$p(0) = Pr(no red balls) = (1-0.2)^9 = 0.1342$$ 

$$p(1) = Pr(1 red ball) = 9*(0.2*(1-0.2)^8) = 0.302 $$

$$P(2) = Pr(2 red balls) = (9!/2!*7!)*(0.2^2)*(0.8^7) = 0.302$$

Example: let Pr(mouse survival treatment) = 90%, apply this treatment to 10 random mice.

$$Pr(7 mice survive) = p(7) = (10!/7!*3!)*0.9^7*0.1^3 = 120*0.9^7*0.1^3 = 0.0574 $$
$$Pr(fewer than 9 survive) = 1-p(10)-p(9) = 1- (0.9^10) - (10*0.9^9*0.1) = 0.2639 $$


### Expected Value (E/μ) and Standard Deviation (SD/σ)

Expected value/mean of a discrete random variable X with probability function p(x)

$$μ=E(x)=∑_x▒x p(x)$$

Variance of a discrete random variable X with probability function p(x)

$$σ^2=var(X)=∑_x▒〖(x−μ)^2 p(x) 〗$$

Standard Deviation (SD) of X

$$σ=SD(X)= √(var(X))$$

Discrete Random Variables


Joint Distribution

p_XY (x,y)=Pr⁡(X=x and Y=y)

Marginal Distributions

p_X (x)=Pr⁡(X=x)=∑_y▒〖p_XY (x,y)〗  -> sum by columns

p_Y (y)=Pr⁡(Y=y)=∑_x▒〖p_XY (x,y)〗  -> sum by rows

Conditional Distributions

p_(X|Y=y) (x)=Pr⁡(X=x│Y=y)=(p_XY (x,y))/(p_Y (y) )  -> given Y = y, the probability of X

Independence

We say X and Y are independent, if p_XY (x,y)=p_X (x) p_Y (y)  for every pair x,y.

Equivalently… Pr⁡(X=x│Y=y)=Pr⁡(X=x)  for every pair x,y.

Continuous Random Variables

Joint densities: f_XY (x,y)

Marginal Densities: f_X (x)=∫▒〖f_XY (x,y)dy〗  and f_Y (y)=∫▒〖f_XY (x,y)dx〗

Conditional Densities: f_(X|Y=y) (x)=(f_XY (x,y))/(f_Y (y))

X and Y are independent if f_XY (x,y)=f_X (x) f_Y (y)  

IID: Independent and Identically Distributed

Random variables X_1, X_2, X_3, …X_n  are said to be independent and identically distributted (iid) if they are independet, and they all have the same distribution.

	• Usually generated by repeated independent measurements, 
	
	• or random sampling from a large population. 
	
Means (E) and SDs of …

Sums of random variables:

	• E(∑_i▒X_i )=∑_i▒E(X_i )    no matter what;
	
	• SD(∑_i▒X_i )=√(∑_i▒{SD(X_i )}^2 )  If the X_i  are independent.
	
Means of random variables:

- $E(∑_i▒X_i /n)=∑_i▒〖E(X_i )/n〗$   no matter what;
	
- $SD(∑_i▒X_i /n)=√(∑_i▒{SD(X_i )}^2 )/n $ If the X_i  are independent.
	
If the X_i  are iid with mean μ and SD σ:

$$E(∑_i▒〖X_i/n〗)=μ  and SD(∑_i▒X_i/n)=σ/√n$$
	
## Credit

-   **STAT 503** Statistical Methods for Biology *by* Dr. Yan Xing

-   **140.615/616** Statistics for Lab Scientists I & II *by* Dr. Ingo Ruczinski

-   **STATS 101** Introduction to Applied Statistics *by* Dr. Andrew MacDonald


---

I decide to write my stats notes taken from those classes into easy-to-read articles and publish them, since I want to get an A in the stats class I'm taking this semester, practice typing *LaTex*, and have a quick reference whenever needed rather than search for 'how to perform ANOVA in R' by Google.

> The saying goes, *'学好数理化，走遍天下都不怕'（from Maths, Physics and Chemistry to anywhere in the world）* ;
>
> And the saying also goes *'基础不牢，地动山摇'（your life would suck if your STEM foundation sucks）*
